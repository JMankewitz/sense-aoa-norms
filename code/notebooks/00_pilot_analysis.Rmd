---
title: "01_pilot_analysis"
author: "Jessica Mankewitz"
date: "2/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(dplyr.summarise.inform = FALSE)
```

How many estimations have we collected? What is the distribution of those estimations? Are there senses we need to target further?

How many estimations do we need for quality estimations w/o modeling or norming?

# Setup
```{r}
library(here)
library(ggplot2)
library(patchwork)
library(tidyverse)
library(rcompanion)

set.seed(1000)

read_path <- here("data/processed_data/")
write_path <- here("data/derived_data/")
fig_path <- here("figures/")
```

# Read in data
```{r message=FALSE, warning=FALSE}
attention_checks.df <- read_csv(file = paste0(read_path, "raw_attention_checks.csv"),
                                col_types = cols(aoa = col_character()))
raw_lemma_estimations.df <- read_csv(file = paste0(read_path, "raw_lemma_estimations.csv"),
                                col_types = cols(aoa = col_character()))
raw_sense_estimations.df <- read_csv(file = paste0(read_path, "raw_sense_estimations.csv"),
                                col_types = cols(aoa = col_character()))
raw_demographics <- read_csv(paste0(read_path, "demographics.csv"))
```

# Drop attention checks
```{r}
# Drop any participant who failed at least one attention check
failed_attention_participants <-raw_demographics %>% select(participant_id, finished) %>% left_join(attention_checks.df) %>% 
  filter(aoa != "7" | is.na(aoa)) %>% distinct(participant_id) %>% deframe()

dropped_non_eng_fl <- raw_demographics %>% filter(eng_first_lang != "Yes") %>%
  distinct(participant_id) %>% deframe()

lemma_estimations.df <- raw_lemma_estimations.df %>% 
  filter(!participant_id %in% failed_attention_participants,
         !participant_id %in% dropped_non_eng_fl)
sense_estimations.df <- raw_sense_estimations.df %>% 
  filter(!participant_id %in% failed_attention_participants,
         !participant_id %in% dropped_non_eng_fl)
demographics.df <- raw_demographics %>%
  filter(!participant_id %in% failed_attention_participants)
```

We're dropping all participants who failed at least one attention check (n = `r length(failed_attention_participants)`) or reported a first language other than english (n = `r length(dropped_non_eng_fl)`). n = `r length(unique(demographics.df$participant_id))` remaining

# By Lemma Analysis
Get all of the lemmas that were designated as calibration items (lemmas for attention checks and shared lemmas)

```{r}
shared_lemma_estimations.df <- lemma_estimations.df %>% 
  filter(grepl("calib", group) | grepl("attn", group),
         aoa != "x") %>%
  mutate(aoa = as.numeric(aoa)) %>%
  #if a participant tagged a lemma twice, average lemma estimations
  group_by(participant_id,lemma) %>%
  summarise_at("aoa",list(aoa = mean))
```

```{r}
shared_lemma_estimations.df %>% ggplot(aes(x = aoa)) +
  geom_density(adjust = 1.75, aes(group = lemma, fill = lemma), alpha = .35) + 
theme_minimal() + labs(title = "Age of Acquisition Data Across Shared/Calibration Lemmas",
                                  subtitle = "Before Calibrating Participants",
                                  xlab='AoA Estimation',
                                  ylab='Num Estimations')

shared_lemma_estimations.df %>% ggplot(aes(x = aoa)) +
 geom_density(aes(fill = lemma), adjust = 1.5) + 
theme_minimal() + labs(title = "Age of Acquisition Data Across Shared/Calibration Lemmas",
                                  subtitle = "Before Calibrating Participants",
                                  xlab='AoA Estimation',
                                  ylab='Num Estimations') +
  facet_wrap(~lemma)

#raincloud plot?
source("https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R")

shared_lemma_estimations.df %>% ggplot(aes(y = aoa, x = reorder(lemma, aoa, FUN = mean), fill = lemma)) + 
  geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .8, adjust = 1.5) + coord_flip() + 
  geom_point(aes(y= aoa, color = lemma), 
             position = position_jitter(height = .25, width = .1), 
             size = .5,
             alpha = .8) + 
  geom_boxplot(width = .1, outlier.shape = NA, alpha = .5) + 
  expand_limits(x = 5.25) + theme_classic() + guides(fill = FALSE, color = FALSE) + 
  labs(title = "AoA Estimations for Shared Lemmas") + ylab("Estimated AoA") + xlab("Lemma")
```
Look at the average aoa by item for calibration items (the cool many lines graph)

```{r}
shared_lemma_estimations.df %>% ggplot(aes(x = reorder(lemma, aoa, FUN = mean), y = aoa)) + 
  geom_line(aes(group =  interaction(participant_id)), alpha = .05) + 
  #stat_summary(fun.data = 'mean_cl_boot', color = "blue", size = .25)  +
  
  stat_summary(fun = mean, geom="line", group = 1, color = "#009f89", size = 1) +
stat_summary(fun = mean, geom="point", group = 1, fill = "#009f89", color = "#009f89", size = 4) + theme_minimal() + 
  labs(title = "Mean AoA Estimations",
       subtitle = "For Shared Lemmas") +
  ylab("Age of Acquisition Estimation") + 
  theme(axis.title.x=element_blank())
```

```{r}
shared_lemma_estimations.df %>% group_by(lemma) %>% summarize(mean = mean(aoa))
```

```{r}
lemma_estimations.df %>% 
  filter(aoa != "x") %>%
  mutate(aoa = as.numeric(aoa)) %>%
  #if a participant tagged a lemma twice, average lemma estimations
  #TODO: Try selecting the first instance of the lemma that was seen - need to do some order preprocessing.
  group_by(participant_id,lemma) %>%
  summarise_at("aoa",list(aoa = mean)) %>%
  group_by(lemma) %>%
  mutate(num_estimations = n()) %>%
  ungroup() %>% filter(num_estimations >= 100)  %>% ggplot(aes(y = aoa, x = reorder(lemma, aoa, FUN = mean), fill = lemma)) + 
  #geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .8, adjust = 1.5) +
  coord_flip() + 
  geom_point(aes(y= aoa, color = lemma), 
             position = position_jitter(height = .25, width = .1), 
             size = .5,
             alpha = .8) + 
  geom_boxplot(width = .1, outlier.shape = NA, alpha = .5) + 
  expand_limits(x = 5.25) + theme_classic() + guides(fill = FALSE, color = FALSE) + 
  labs(title = "AoA Estimations",
       subtitle = "Lemmas with >100 estimations") + ylab("Estimated AoA") + xlab("Lemma")
```

```{r}
kuperman_estimations  <- read.csv(here("data/predictors/kuperman_aoa_ratings.csv"))

kuperman_estimations <- kuperman_estimations %>% filter(Word %in% lemma_estimations.df$lemma) %>% select("Word", "Rating.Mean") %>% rename(
    lemma = Word,
    kuperman_aoa = Rating.Mean
    )

wordbank_estimations <- read.csv(here("data/predictors/wordbank_aoa.csv")) %>% select("uni_lemma", "aoa")
wordbank_estimations$aoa <- wordbank_estimations$aoa/365.5
wordbank_estimations <- wordbank_estimations %>% filter(uni_lemma %in% lemma_estimations.df$lemma)

wordbank_estimations$aoa <- as.numeric(wordbank_estimations$aoa)
#collapse across polysemy
wordbank_estimations <- wordbank_estimations %>%
  group_by(uni_lemma) %>% 
  summarize_at("aoa", list(aoa=mean)) %>% 
  rename(wordbank_aoa = aoa, lemma = uni_lemma)

comparison.df <- lemma_estimations.df %>% 
  filter(aoa != "x") %>%
  mutate(aoa = as.numeric(aoa)) %>%
  #if a participant tagged a lemma twice, average lemma estimations
  group_by(participant_id,lemma) %>%
  summarise_at("aoa",list(aoa = mean)) %>%
  group_by(lemma) %>%
  summarize(num_estimations = n(), our_mean_aoa = mean(aoa)) %>%
  ungroup() %>%
  left_join(kuperman_estimations) %>% 
  left_join(wordbank_estimations)
```

Set up comparisons
```{r}
theme_set(theme_minimal())
text_labels <- geom_text(aes(label=lemma),hjust=-.2, vjust=.25,check_overlap = TRUE, alpha=.75)

ours_v_kuperman_r2 <- round(summary(lm(our_mean_aoa~kuperman_aoa, comparison.df))$r.squared[1], 3)

ours_v_kuperman <- comparison.df %>% ggplot(aes(x = our_mean_aoa, y = kuperman_aoa)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm", formula = y~x) +
    labs(title = "Our Estimations vs Kuperman",
       subtitle = paste("R^2 = ",  ours_v_kuperman_r2),
       y='Kuperman',
       x='Our Estimations')
```

```{r}
ours_v_wordbank_r2 <- round(summary(lm(our_mean_aoa~wordbank_aoa, comparison.df))$r.squared[1], 3)

ours_v_wordbank <- comparison.df %>% ggplot(aes(x = our_mean_aoa, y = wordbank_aoa)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm", formula = y~x) +
    labs(title = "Our Estimations vs Wordbank",
       subtitle = paste("R^2 = ",  ours_v_wordbank_r2),
       y='Wordbank (50% Producing)',
       x='Our Estimations')
```
```{r}
kuperman_v_wordbank_r2 <- round(summary(lm(kuperman_aoa~wordbank_aoa, comparison.df))$r.squared[1], 3)

kuperman_v_wordbank <- comparison.df %>% ggplot(aes(x = kuperman_aoa, y = wordbank_aoa)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm", formula = y~x) +
    labs(title = "Wordbank vs Kuperman",
       subtitle = paste("R^2 = ",  kuperman_v_wordbank_r2),
       y='Wordbank (50% Producing)',
       x='Kuperman')
```

```{r}
(ours_v_kuperman + ours_v_wordbank) / kuperman_v_wordbank + 
  plot_layout(widths = c(1, 1, 2))

ggsave(filename = paste0(fig_path, "comparisons_raw.png"), height = 4, width = 6)

```

Filter to lemmas with >50 tags
```{r}
theme_set(theme_minimal())
text_labels <- geom_text(aes(label=lemma),hjust=-.2, vjust=.25,check_overlap = TRUE, alpha=.75)

cutoff = 30
target.df <- comparison.df %>% filter(num_estimations >= cutoff)

ours_v_kuperman_r2 <- round(summary(lm(our_mean_aoa~kuperman_aoa, target.df))$r.squared[1], 3)

ours_v_kuperman <- target.df %>% ggplot(aes(x = our_mean_aoa, y = kuperman_aoa)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm", formula = y~x) +
    labs(title = "Our Estimations vs Kuperman",
       subtitle = paste0(">", cutoff, " estimations; R^2 = ",  ours_v_kuperman_r2),
       y='Kuperman',
       x='Our Estimations') + text_labels

ours_v_wordbank_r2 <- round(summary(lm(our_mean_aoa~wordbank_aoa, target.df))$r.squared[1], 3)

ours_v_wordbank <- target.df %>% ggplot(aes(x = our_mean_aoa, y = wordbank_aoa)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm", formula = y~x) +
    labs(title = "Our Estimations vs Wordbank",
       subtitle = paste0(">", cutoff, " estimations; R^2 = ",  ours_v_wordbank_r2),
       y='Wordbank (50% Producing)',
       x='Our Estimations')

kuperman_v_wordbank_r2 <- round(summary(lm(kuperman_aoa~wordbank_aoa, target.df))$r.squared[1], 3)

kuperman_v_wordbank <- target.df %>% ggplot(aes(x = kuperman_aoa, y = wordbank_aoa)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm", formula = y~x) +
    labs(title = "Wordbank vs Kuperman",
       subtitle = paste0(">", cutoff, " estimations; R^2 = ",  kuperman_v_wordbank_r2),
       y='Wordbank (50% Producing)',
       x='Kuperman')
```

```{r}
(ours_v_kuperman + ours_v_wordbank) / kuperman_v_wordbank + 
  plot_layout(widths = c(1, 1, 2))

ggsave(filename = paste0(fig_path, "comparisons_threshold.png"), height = 4, width = 6)
```

Bootstrap - How many estimations are needed to replicate Kuperman?

For the same set of lemmas with >50 estimations
```{r}
# make a function that takes in a number, randomly selects that many estimations and returns the means 

randomly_sample <- function(sample, estimation_df, replace = FALSE){
  comparison.df <- estimation_df %>% 
  filter(aoa != "x") %>%
  mutate(aoa = as.numeric(aoa)) %>%
  #if a participant tagged a lemma twice, average lemma estimations
  group_by(participant_id,lemma, kuperman_aoa) %>%
  summarise_at("aoa",list(aoa = mean)) %>%
    group_by(lemma) %>%
    mutate(num_estimations = n()) %>%
    ungroup() %>%
    group_by(lemma, kuperman_aoa) %>%
    sample_n(sample, replace = replace) %>%
    summarize(our_mean_aoa = mean(aoa)) %>%
    mutate(sample = sample) %>% 
    ungroup()
  
  r_2 = round(summary(lm(kuperman_aoa~our_mean_aoa, comparison.df))$r.squared[1], 3)
  comparison.df$r_2 <- r_2
  return(comparison.df)
}

sample_intervals <- c(1, 5, 10, 15, 25, 50, 100, 500, 1000)

sample_combinations<- lapply(sample_intervals, randomly_sample,
                             lemma_estimations.df  %>%
                               left_join(comparison.df) %>%
                                filter(num_estimations >= cutoff), replace = TRUE)

sample_combinations <- do.call(rbind, sample_combinations)

sample_combinations %>% mutate(samples = paste0("n = ", sample))%>% ggplot(aes(x = our_mean_aoa, y = kuperman_aoa)) +
  geom_point(aes(color = factor(sample)), alpha = .5) +
  geom_smooth(aes(color = factor(sample)), method = "lm", formula = y~x) +
    labs(title = "Mean AoA from n Sampled Estimations per lemma",
         subtitle = "Sampled with replacement, lemmas with > 30 tags",
       y='Kuperman',
       x='Our Estimations') + 
  geom_text(aes(label=lemma, color = factor(sample)), hjust=-.2, vjust=.25,
            check_overlap = TRUE, alpha=.8) +
  geom_text(data = sample_combinations %>% mutate(samples = paste0("n = ", sample))%>% group_by(sample, r_2) %>% summarize(min_x = min(our_mean_aoa)), 
            aes(label = paste0("r^2 = ", r_2), x = min_x, y =6), hjust = 0) + 
  guides(color = FALSE)  + facet_wrap(~sample, scales = "free") + ylim(1,6) + theme_minimal() +
  theme(strip.text = element_text(size = 12))

ggsave(filename = paste0(fig_path, "bootstraped_samples.png"), height = 6, width = 6)
```
What is the range of r^2 for each sample num after 1000 iterations of each sample?

```{r message=FALSE, cache = TRUE}
# run sample_combinations 1000 times for each n, calculating r^2 each time

bootstrap_r_2 <- function(sample, iterations, estimation_df, replace = FALSE){
  # get sample
  print(sample)
  sample_iterations <- rep(sample, iterations)
  sample_combinations <- lapply(sample_iterations, randomly_sample, estimation_df, replace = replace)
  sample_combinations <- do.call(rbind, sample_combinations) %>% filter(lemma == "ball") %>% select(sample, r_2)
return(sample_combinations)
}

sample_intervals <- c(1, 5, 10, 15, 25, 50, 100, 500, 1000)

#cache the values
#  bootstrapped_samples <- lapply(sample_intervals, bootstrap_r_2, 1000, lemma_estimations.df  %>%
#                                 left_join(comparison.df) %>%
#                                 filter(num_estimations >= cutoff), replace = TRUE)
# 
#  bootstrapped_samples <- do.call(rbind, bootstrapped_samples)
# saveRDS(bootstrapped_samples, file = paste0(write_path, "bootstrapped_1000.RData"))
```

```{r}
bootstrapped_samples <- readRDS(file = paste0(write_path, "bootstrapped_1000.RData"))
bootstrapped_samples %>% ggplot() +  geom_density(aes(x = r_2)) + facet_wrap(~sample, scales = "free_y")

bootstrapped_samples %>% ggplot(aes(y = r_2, x = factor(sample),  fill = factor(sample))) + 
  geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .8, adjust = 1.5) + coord_flip() + 
  geom_point(aes(y= r_2, color = factor(sample)), 
             position = position_jitter(height = .0, width = .1), 
             size = .5,
             alpha = .5) + 
  geom_boxplot(width = .1, outlier.shape = NA, alpha = .5) + 
  expand_limits(x = 5.25) + theme_classic() + guides(fill = FALSE, color = FALSE) + 
  labs(title = "r^2 for n samples after 1000 iterations") + ylab("r^2") + xlab("Sample")

ggsave(filename = paste0(fig_path, "sample_iterations.png"), height = 4, width = 6)
```

Subsample without replacement for lemmas with at least 30 estimations
```{r}
subsample_intervals <- c(1, 5, 10, 15, 20, 30)
cutoff <- 30
subsample_combinations<- lapply(subsample_intervals, randomly_sample, 
                             lemma_estimations.df  %>%
                               left_join(comparison.df) %>%
                               filter(num_estimations >= cutoff), replace = FALSE)

subsample_combinations <- do.call(rbind, subsample_combinations)

subsample_combinations %>% mutate(samples = paste0("n = ", sample))%>% ggplot(aes(x = our_mean_aoa, y = kuperman_aoa)) +
  geom_point(aes(color = factor(sample)), alpha = .5) +
  geom_smooth(aes(color = factor(sample)), method = "lm", formula = y~x) +
    labs(title = "Mean AoA from n Sampled Estimations per lemma",
         subtitle = "Sampled without replacement for lemmas with >30",
       y='Kuperman',
       x='Our Estimations') + 
  geom_text(aes(label=lemma, color = factor(sample)), hjust=-.2, vjust=.25,
            check_overlap = TRUE, alpha=.8) +
  geom_text(data = subsample_combinations %>% mutate(samples = paste0("n = ", sample))%>% group_by(sample, r_2) %>% summarize(min_x = min(our_mean_aoa)), 
            aes(label = paste0("r^2 = ", r_2), x = min_x, y =6), hjust = 0) + 
  guides(color = FALSE)  + facet_wrap(~sample, scales = "free") + ylim(1,6) + theme_minimal() +
  theme(strip.text = element_text(size = 12))

ggsave(filename = paste0(fig_path, "bootstraped_subsamples.png"), height = 6, width = 6)
```

```{r}
#cache the values

# subsample_intervals <- c(1, 5, 10, 15, 20, 30)
# 
# bootstrapped_subsamples <- lapply(subsample_intervals, bootstrap_r_2, 100,
#                                    lemma_estimations.df  %>%
#                                left_join(comparison.df) %>%
#                                filter(num_estimations >= cutoff), replace = FALSE)
# #
# bootstrapped_subsamples <- do.call(rbind, bootstrapped_subsamples)
# saveRDS(bootstrapped_subsamples, file = paste0(write_path, "bootstrapped_subsamples_100.RData"))
```

```{r}
bootstrapped_subsamples <- readRDS(file = paste0(write_path, "bootstrapped_subsamples_100.RData"))
bootstrapped_subsamples %>% ggplot() +  geom_density(aes(x = r_2)) + facet_wrap(~sample, scales = "free_y")

bootstrapped_subsamples %>% ggplot(aes(y = r_2, x = factor(sample),  fill = factor(sample))) + 
  geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .8, adjust = 1.5) + coord_flip() + 
  geom_point(aes(y= r_2, color = factor(sample)), 
             position = position_jitter(height = 0, width = .1), 
             size = .5,
             alpha = .5) + 
  geom_boxplot(width = .1, outlier.shape = NA, alpha = .5) + 
  expand_limits(x = 5.25) + theme_classic() + guides(fill = FALSE, color = FALSE) + 
  labs(title = "100 iterations of r^2 for n samples") + ylab("r^2") + xlab("Sample")

ggsave(filename = paste0(fig_path, "sample_iterations.png"), height = 4, width = 6)
```

# Estimating AoA

```{r eval=FALSE, include=FALSE}
lemma_estimations.df
sense_estimations.df

CIs <- groupwiseMean(aoa ~ lemma,
                         data   = lemma_estimations.df,
                         conf   = 0.95,
                         digits = 5,
                         R      = 10000,
                         boot        = TRUE,
                         traditional = FALSE,
                         normal      = FALSE,
                         basic       = FALSE,
                         percentile  = FALSE,
                         bca         = TRUE)
CIs
```
```{r}
CIs %>% left_join(kuperman_estimations, by = c("lemma"))
```

